{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "#import utils\n",
    "#importlib.reload(utils)\n",
    "from sent_sampling.utils.data_utils import SENTENCE_CONFIG\n",
    "from neural_nlp.models import model_pool\n",
    "import utils.extract_utils\n",
    "importlib.reload(utils.extract_utils)\n",
    "from sent_sampling.utils.extract_utils import model_extractor_parallel\n",
    "\n",
    "from neural_nlp.utils import ordered_set\n",
    "from neural_nlp.stimuli import load_stimuli, StimulusSet\n",
    "from neural_nlp.models import model_pool, model_layers\n",
    "from neural_nlp import FixedLayer\n",
    "from brainio_base.assemblies import DataAssembly, walk_coords, merge_data_arrays, array_is_element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset='ud_sentencez_token_filter_v3_sample'\n",
    "#dataset='coca_spok_filter_punct_sample'\n",
    "datafile=[x['file_loc'] for x in SENTENCE_CONFIG if x['name']==dataset][0]\n",
    "model_name='gpt2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 82388.11it/s]\n",
      "22it [00:00, 52608.15it/s]\n",
      "22it [00:00, 27860.71it/s]\n",
      "22it [00:00, 26839.64it/s]\n",
      "23it [00:00, 29710.19it/s]\n",
      "22it [00:00, 28674.55it/s]\n",
      "22it [00:00, 28630.06it/s]\n",
      "22it [00:00, 28132.53it/s]\n",
      "23it [00:00, 28693.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /om/user/ehoseini/MyData/Universal Dependencies 2.6/ud_sentencez_data_token_filter_sample_v3_no_dup.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test=model_extractor_parallel(dataset=dataset,datafile=datafile,model_spec=model_name,average_sentence=False)\n",
    "\n",
    "test.load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_set=test.extractor.stimuli_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_impl = model_pool[test.model_spec]\n",
    "layers = model_layers[test.model_spec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "candidate = FixedLayer(model_impl, layers[0], prerun=layers if i==0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-22 : He could n't count the number of capital ships that dominated the Enemy 's frontline\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87afaf453244c9493ac295f8845cb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=665.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d5d62cdc3947a6829e3a690b590d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1042301.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a9f0fa7de44fab9c4737ec32c5443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12ec5499c6245f78536e1d47fd03e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=548118077.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cls_token, but it is not set yet.\n",
      "token features: 100%|██████████| 17/17 [00:03<00:00,  5.62it/s]\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 87.24it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-23 : Well a changing bag would be the easiest solution\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 9/9 [00:01<00:00,  6.19it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.27it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-24 : All this is highly unlikely , as with most al - Qaeda crackpot schemes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 15/15 [00:02<00:00,  5.94it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.55it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-25 : Bush successfully makes Satan look good in comparison\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 8/8 [00:01<00:00,  6.40it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 95.25it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:  29%|██▊       | 2/7 [00:00<00:00, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-26 : Carve one in your chosen medium\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 7/7 [00:01<00:00,  6.86it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.47it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-27 : The clock on the wall opposite him had only one hand and no numbers at all\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 16/16 [00:02<00:00,  5.35it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.77it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-28 : Thank you , Mr Kinnock\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 6/6 [00:00<00:00,  8.36it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 95.85it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-29 : In the parts of the city farther from downtown , north-south streets are numbered\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 16/16 [00:02<00:00,  6.26it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 95.32it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-30 : I am no fanatical defender of profits for pharmaceutical industry multinationals\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 13/13 [00:01<00:00,  6.66it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.42it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-31 : We also know that he wrote books\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 7/7 [00:01<00:00,  6.36it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.10it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-32 : In the Harry Potter series written by JK Rowling the main wizarding sport is Quidditch\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 19/19 [00:02<00:00,  6.66it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 93.37it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-33 : I just got your email and I certainly concur with Jeff making the call\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 15/15 [00:02<00:00,  5.87it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 93.63it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-34 : His mother was also killed in the attack\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 8/8 [00:01<00:00,  6.33it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 95.29it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-35 : China launched Shenzhou VI , its second manned spacecraft , early today in northwest China 's Gansu Province\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 22/22 [00:03<00:00,  6.12it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 95.27it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-36 : The Commission 's estimates of what would be health-endangering values reflect the outcome of the research carried out\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 22/22 [00:03<00:00,  5.96it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 95.68it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-37 : I do the sum and the answer is an incipient third\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 12/12 [00:01<00:00,  6.44it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 90.16it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-38 : Depending on the adjusters , you may be able to leave them a little loose too\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 17/17 [00:03<00:00,  5.57it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.98it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-39 : This may be an attempt to play dead , discouraging predators that prefer live prey\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 15/15 [00:02<00:00,  5.43it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 93.89it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-40 : Syria is surrounded by Turkey , Iraq , Jordan and Israel\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 11/11 [00:01<00:00,  5.91it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 90.42it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-41 : Oh , if you are confused\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 6/6 [00:00<00:00,  6.72it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 49.86it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-42 : The store is clean , run very professionally and a pleasure to be in\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 14/14 [00:02<00:00,  5.55it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.88it/s]\n",
      "Using cls_token, but it is not set yet.\n",
      "token features:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_1-43 : I do n't feel anything until noon\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "token features: 100%|██████████| 8/8 [00:01<00:00,  7.30it/s]\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 94.47it/s]\n"
     ]
    }
   ],
   "source": [
    "reset_column='sentence_id'\n",
    "copy_columns=['stimulus_id']\n",
    "activations = []\n",
    "for i, reset_id in enumerate(ordered_set(stimulus_set[reset_column].values)):\n",
    "    part_stimuli = stimulus_set[stimulus_set[reset_column] == reset_id]\n",
    "    stimulus_ids = part_stimuli['stimulus_id']\n",
    "    sentence_stimuli = StimulusSet({'sentence': ' '.join(part_stimuli['word']),\n",
    "                                        reset_column: list(set(part_stimuli[reset_column]))})\n",
    "    sentence_stimuli.name = f\"{stimulus_set.name}-{reset_id}\"\n",
    "    print(f\"running {sentence_stimuli.name} : {' '.join(part_stimuli['word'])}\\n\")\n",
    "    sentence_activations = candidate(stimuli=sentence_stimuli, average_sentence=False)\n",
    "    for column in copy_columns:\n",
    "            sentence_activations[column] = ('presentation', part_stimuli[column])\n",
    "    activations.append(sentence_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_activations = merge_data_arrays(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "layers:   0%|          | 0/13 [00:00<?, ?it/s]Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_0_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  12%|█▏        | 2/17 [00:00<00:01,  7.81it/s]\u001b[A\n",
      "token features:  18%|█▊        | 3/17 [00:00<00:01,  7.10it/s]\u001b[A\n",
      "token features:  24%|██▎       | 4/17 [00:00<00:01,  6.67it/s]\u001b[A\n",
      "token features:  29%|██▉       | 5/17 [00:00<00:01,  6.17it/s]\u001b[A\n",
      "token features:  35%|███▌      | 6/17 [00:00<00:01,  5.83it/s]\u001b[A\n",
      "token features:  41%|████      | 7/17 [00:01<00:01,  5.62it/s]\u001b[A\n",
      "token features:  47%|████▋     | 8/17 [00:01<00:01,  5.50it/s]\u001b[A\n",
      "token features:  53%|█████▎    | 9/17 [00:01<00:01,  5.10it/s]\u001b[A\n",
      "token features:  65%|██████▍   | 11/17 [00:01<00:01,  5.89it/s]\u001b[A\n",
      "token features:  71%|███████   | 12/17 [00:02<00:00,  5.44it/s]\u001b[A\n",
      "token features:  76%|███████▋  | 13/17 [00:02<00:00,  5.00it/s]\u001b[A\n",
      "token features:  82%|████████▏ | 14/17 [00:02<00:00,  4.73it/s]\u001b[A\n",
      "token features:  88%|████████▊ | 15/17 [00:02<00:00,  4.48it/s]\u001b[A\n",
      "token features:  94%|█████████▍| 16/17 [00:02<00:00,  4.36it/s]\u001b[A\n",
      "token features: 100%|██████████| 17/17 [00:03<00:00,  5.21it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 88.53it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  20%|██        | 2/10 [00:00<00:00,  9.37it/s]\u001b[A\n",
      "token features:  30%|███       | 3/10 [00:00<00:00,  8.07it/s]\u001b[A\n",
      "token features:  40%|████      | 4/10 [00:00<00:00,  7.34it/s]\u001b[A\n",
      "token features:  50%|█████     | 5/10 [00:00<00:00,  6.59it/s]\u001b[A\n",
      "token features:  60%|██████    | 6/10 [00:00<00:00,  6.15it/s]\u001b[A\n",
      "token features:  70%|███████   | 7/10 [00:01<00:00,  5.81it/s]\u001b[A\n",
      "token features:  80%|████████  | 8/10 [00:01<00:00,  5.50it/s]\u001b[A\n",
      "token features:  90%|█████████ | 9/10 [00:01<00:00,  4.91it/s]\u001b[A\n",
      "token features: 100%|██████████| 10/10 [00:01<00:00,  5.57it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 87.46it/s][A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "token features:  18%|█▊        | 2/11 [00:00<00:00, 12.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  27%|██▋       | 3/11 [00:00<00:00,  9.38it/s]\u001b[A\n",
      "token features:  36%|███▋      | 4/11 [00:00<00:00,  8.00it/s]\u001b[A\n",
      "token features:  45%|████▌     | 5/11 [00:00<00:01,  5.78it/s]\u001b[A\n",
      "token features:  55%|█████▍    | 6/11 [00:00<00:00,  5.61it/s]\u001b[A\n",
      "token features:  64%|██████▎   | 7/11 [00:01<00:00,  5.49it/s]\u001b[A\n",
      "token features:  73%|███████▎  | 8/11 [00:01<00:00,  5.36it/s]\u001b[A\n",
      "token features:  82%|████████▏ | 9/11 [00:01<00:00,  5.10it/s]\u001b[A\n",
      "token features:  91%|█████████ | 10/11 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "token features: 100%|██████████| 11/11 [00:02<00:00,  5.47it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 87.52it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  29%|██▊       | 2/7 [00:00<00:00,  9.08it/s]\u001b[A\n",
      "token features:  43%|████▎     | 3/7 [00:00<00:00,  7.81it/s]\u001b[A\n",
      "token features:  57%|█████▋    | 4/7 [00:00<00:00,  7.11it/s]\u001b[A\n",
      "token features:  71%|███████▏  | 5/7 [00:00<00:00,  6.41it/s]\u001b[A\n",
      "token features:  86%|████████▌ | 6/7 [00:00<00:00,  5.99it/s]\u001b[A\n",
      "token features: 100%|██████████| 7/7 [00:01<00:00,  6.13it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 86.83it/s][A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  18%|█▊        | 2/11 [00:00<00:00,  9.08it/s]\u001b[A\n",
      "token features:  27%|██▋       | 3/11 [00:00<00:01,  7.79it/s]\u001b[A\n",
      "token features:  36%|███▋      | 4/11 [00:00<00:00,  7.06it/s]\u001b[A\n",
      "token features:  45%|████▌     | 5/11 [00:00<00:00,  6.43it/s]\u001b[A\n",
      "token features:  55%|█████▍    | 6/11 [00:00<00:00,  6.03it/s]\u001b[A\n",
      "token features:  64%|██████▎   | 7/11 [00:01<00:00,  5.77it/s]\u001b[A\n",
      "token features:  73%|███████▎  | 8/11 [00:01<00:00,  5.60it/s]\u001b[A\n",
      "token features:  82%|████████▏ | 9/11 [00:01<00:00,  5.27it/s]\u001b[A\n",
      "token features:  91%|█████████ | 10/11 [00:01<00:00,  5.07it/s]\u001b[A\n",
      "token features: 100%|██████████| 11/11 [00:01<00:00,  5.57it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.94it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/18 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  11%|█         | 2/18 [00:00<00:01,  8.94it/s]\u001b[A\n",
      "token features:  17%|█▋        | 3/18 [00:00<00:01,  7.76it/s]\u001b[A\n",
      "token features:  22%|██▏       | 4/18 [00:00<00:01,  7.09it/s]\u001b[A\n",
      "token features:  33%|███▎      | 6/18 [00:00<00:01,  7.86it/s]\u001b[A\n",
      "token features:  39%|███▉      | 7/18 [00:00<00:01,  6.84it/s]\u001b[A\n",
      "token features:  44%|████▍     | 8/18 [00:01<00:01,  6.27it/s]\u001b[A\n",
      "token features:  50%|█████     | 9/18 [00:01<00:01,  5.70it/s]\u001b[A\n",
      "token features:  56%|█████▌    | 10/18 [00:01<00:01,  5.35it/s]\u001b[A\n",
      "token features:  61%|██████    | 11/18 [00:01<00:01,  5.13it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 12/18 [00:01<00:01,  4.97it/s]\u001b[A\n",
      "token features:  78%|███████▊  | 14/18 [00:02<00:00,  5.68it/s]\u001b[A\n",
      "token features:  83%|████████▎ | 15/18 [00:02<00:00,  5.15it/s]\u001b[A\n",
      "token features:  89%|████████▉ | 16/18 [00:02<00:00,  4.86it/s]\u001b[A\n",
      "token features:  94%|█████████▍| 17/18 [00:02<00:00,  4.56it/s]\u001b[A\n",
      "token features: 100%|██████████| 18/18 [00:03<00:00,  5.60it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.36it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  19%|█▉        | 3/16 [00:00<00:00, 13.67it/s]\u001b[A\n",
      "token features:  25%|██▌       | 4/16 [00:00<00:01,  9.87it/s]\u001b[A\n",
      "token features:  31%|███▏      | 5/16 [00:00<00:01,  7.80it/s]\u001b[A\n",
      "token features:  38%|███▊      | 6/16 [00:00<00:01,  6.83it/s]\u001b[A\n",
      "token features:  44%|████▍     | 7/16 [00:00<00:01,  6.26it/s]\u001b[A\n",
      "token features:  50%|█████     | 8/16 [00:01<00:01,  5.96it/s]\u001b[A\n",
      "token features:  56%|█████▋    | 9/16 [00:01<00:01,  5.51it/s]\u001b[A\n",
      "token features:  62%|██████▎   | 10/16 [00:01<00:01,  5.22it/s]\u001b[A\n",
      "token features:  69%|██████▉   | 11/16 [00:01<00:00,  5.06it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 12/16 [00:02<00:00,  4.93it/s]\u001b[A\n",
      "token features:  81%|████████▏ | 13/16 [00:02<00:00,  4.71it/s]\u001b[A\n",
      "token features:  88%|████████▊ | 14/16 [00:02<00:00,  4.56it/s]\u001b[A\n",
      "token features:  94%|█████████▍| 15/16 [00:02<00:00,  4.41it/s]\u001b[A\n",
      "token features: 100%|██████████| 16/16 [00:02<00:00,  5.42it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 88.73it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  17%|█▋        | 2/12 [00:00<00:01,  9.09it/s]\u001b[A\n",
      "token features:  25%|██▌       | 3/12 [00:00<00:01,  7.81it/s]\u001b[A\n",
      "token features:  33%|███▎      | 4/12 [00:00<00:01,  7.11it/s]\u001b[A\n",
      "token features:  42%|████▏     | 5/12 [00:00<00:01,  6.43it/s]\u001b[A\n",
      "token features:  50%|█████     | 6/12 [00:00<00:00,  6.04it/s]\u001b[A\n",
      "token features:  58%|█████▊    | 7/12 [00:01<00:00,  5.77it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 8/12 [00:01<00:00,  5.63it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 9/12 [00:01<00:00,  5.32it/s]\u001b[A\n",
      "token features:  83%|████████▎ | 10/12 [00:01<00:00,  5.01it/s]\u001b[A\n",
      "token features:  92%|█████████▏| 11/12 [00:01<00:00,  4.89it/s]\u001b[A\n",
      "token features: 100%|██████████| 12/12 [00:02<00:00,  5.47it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.79it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  22%|██▏       | 2/9 [00:00<00:00,  9.04it/s]\u001b[A\n",
      "token features:  44%|████▍     | 4/9 [00:00<00:00,  9.77it/s]\u001b[A\n",
      "token features:  56%|█████▌    | 5/9 [00:00<00:00,  7.79it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 6/9 [00:00<00:00,  6.79it/s]\u001b[A\n",
      "token features:  78%|███████▊  | 7/9 [00:00<00:00,  6.25it/s]\u001b[A\n",
      "token features:  89%|████████▉ | 8/9 [00:01<00:00,  5.93it/s]\u001b[A\n",
      "token features: 100%|██████████| 9/9 [00:01<00:00,  6.60it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 88.80it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  33%|███▎      | 3/9 [00:00<00:00, 13.26it/s]\u001b[A\n",
      "token features:  44%|████▍     | 4/9 [00:00<00:00,  9.57it/s]\u001b[A\n",
      "token features:  56%|█████▌    | 5/9 [00:00<00:00,  7.54it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 6/9 [00:00<00:00,  6.67it/s]\u001b[A\n",
      "token features:  78%|███████▊  | 7/9 [00:00<00:00,  6.16it/s]\u001b[A\n",
      "token features:  89%|████████▉ | 8/9 [00:01<00:00,  5.84it/s]\u001b[A\n",
      "token features: 100%|██████████| 9/9 [00:01<00:00,  6.49it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 88.71it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  12%|█▎        | 2/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
      "token features:  19%|█▉        | 3/16 [00:00<00:01,  7.73it/s]\u001b[A\n",
      "token features:  31%|███▏      | 5/16 [00:00<00:01,  8.40it/s]\u001b[A\n",
      "token features:  38%|███▊      | 6/16 [00:00<00:01,  7.17it/s]\u001b[A\n",
      "token features:  44%|████▍     | 7/16 [00:00<00:01,  6.45it/s]\u001b[A\n",
      "token features:  50%|█████     | 8/16 [00:01<00:01,  6.05it/s]\u001b[A\n",
      "token features:  56%|█████▋    | 9/16 [00:01<00:01,  5.59it/s]\u001b[A\n",
      "token features:  62%|██████▎   | 10/16 [00:01<00:01,  5.30it/s]\u001b[A\n",
      "token features:  69%|██████▉   | 11/16 [00:01<00:00,  5.06it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 12/16 [00:02<00:00,  4.83it/s]\u001b[A\n",
      "token features:  81%|████████▏ | 13/16 [00:02<00:00,  4.65it/s]\u001b[A\n",
      "token features:  88%|████████▊ | 14/16 [00:02<00:00,  4.53it/s]\u001b[A\n",
      "token features:  94%|█████████▍| 15/16 [00:02<00:00,  4.44it/s]\u001b[A\n",
      "token features: 100%|██████████| 16/16 [00:02<00:00,  5.40it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.38it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  22%|██▏       | 2/9 [00:00<00:00,  9.02it/s]\u001b[A\n",
      "token features:  33%|███▎      | 3/9 [00:00<00:00,  7.79it/s]\u001b[A\n",
      "token features:  44%|████▍     | 4/9 [00:00<00:00,  7.12it/s]\u001b[A\n",
      "token features:  56%|█████▌    | 5/9 [00:00<00:00,  6.44it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 6/9 [00:00<00:00,  6.05it/s]\u001b[A\n",
      "token features:  78%|███████▊  | 7/9 [00:01<00:00,  5.75it/s]\u001b[A\n",
      "token features:  89%|████████▉ | 8/9 [00:01<00:00,  5.62it/s]\u001b[A\n",
      "token features: 100%|██████████| 9/9 [00:01<00:00,  5.84it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.02it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  17%|█▋        | 2/12 [00:00<00:01,  8.87it/s]\u001b[A\n",
      "token features:  25%|██▌       | 3/12 [00:00<00:01,  7.74it/s]\u001b[A\n",
      "token features:  33%|███▎      | 4/12 [00:00<00:01,  7.10it/s]\u001b[A\n",
      "token features:  42%|████▏     | 5/12 [00:00<00:01,  6.44it/s]\u001b[A\n",
      "token features:  50%|█████     | 6/12 [00:00<00:00,  6.02it/s]\u001b[A\n",
      "token features:  58%|█████▊    | 7/12 [00:01<00:00,  5.76it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 8/12 [00:01<00:00,  5.61it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 9/12 [00:01<00:00,  5.30it/s]\u001b[A\n",
      "token features:  83%|████████▎ | 10/12 [00:01<00:00,  5.09it/s]\u001b[A\n",
      "token features:  92%|█████████▏| 11/12 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "token features: 100%|██████████| 12/12 [00:02<00:00,  5.46it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.44it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  17%|█▋        | 2/12 [00:00<00:01,  9.15it/s]\u001b[A\n",
      "token features:  25%|██▌       | 3/12 [00:00<00:01,  7.86it/s]\u001b[A\n",
      "token features:  42%|████▏     | 5/12 [00:00<00:00,  8.54it/s]\u001b[A\n",
      "token features:  50%|█████     | 6/12 [00:00<00:00,  7.19it/s]\u001b[A\n",
      "token features:  58%|█████▊    | 7/12 [00:00<00:00,  6.50it/s]\u001b[A\n",
      "token features:  67%|██████▋   | 8/12 [00:01<00:00,  6.10it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 9/12 [00:01<00:00,  5.62it/s]\u001b[A\n",
      "token features:  83%|████████▎ | 10/12 [00:01<00:00,  5.32it/s]\u001b[A\n",
      "token features:  92%|█████████▏| 11/12 [00:01<00:00,  5.11it/s]\u001b[A\n",
      "token features: 100%|██████████| 12/12 [00:01<00:00,  6.01it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.57it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  18%|█▊        | 2/11 [00:00<00:01,  8.71it/s]\u001b[A\n",
      "token features:  27%|██▋       | 3/11 [00:00<00:01,  7.52it/s]\u001b[A\n",
      "token features:  36%|███▋      | 4/11 [00:00<00:01,  6.93it/s]\u001b[A\n",
      "token features:  45%|████▌     | 5/11 [00:00<00:00,  6.37it/s]\u001b[A\n",
      "token features:  55%|█████▍    | 6/11 [00:00<00:00,  5.99it/s]\u001b[A\n",
      "token features:  64%|██████▎   | 7/11 [00:01<00:00,  5.74it/s]\u001b[A\n",
      "token features:  73%|███████▎  | 8/11 [00:01<00:00,  5.59it/s]\u001b[A\n",
      "token features:  82%|████████▏ | 9/11 [00:01<00:00,  5.31it/s]\u001b[A\n",
      "token features:  91%|█████████ | 10/11 [00:01<00:00,  5.10it/s]\u001b[A\n",
      "token features: 100%|██████████| 11/11 [00:01<00:00,  5.56it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.44it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  14%|█▍        | 2/14 [00:00<00:01,  9.13it/s]\u001b[A\n",
      "token features:  21%|██▏       | 3/14 [00:00<00:01,  7.88it/s]\u001b[A\n",
      "token features:  29%|██▊       | 4/14 [00:00<00:01,  7.16it/s]\u001b[A\n",
      "token features:  36%|███▌      | 5/14 [00:00<00:01,  6.47it/s]\u001b[A\n",
      "token features:  43%|████▎     | 6/14 [00:00<00:01,  6.04it/s]\u001b[A\n",
      "token features:  50%|█████     | 7/14 [00:01<00:01,  5.79it/s]\u001b[A\n",
      "token features:  57%|█████▋    | 8/14 [00:01<00:01,  5.64it/s]\u001b[A\n",
      "token features:  64%|██████▍   | 9/14 [00:01<00:00,  5.33it/s]\u001b[A\n",
      "token features:  71%|███████▏  | 10/14 [00:01<00:00,  5.12it/s]\u001b[A\n",
      "token features:  79%|███████▊  | 11/14 [00:01<00:00,  4.98it/s]\u001b[A\n",
      "token features:  86%|████████▌ | 12/14 [00:02<00:00,  4.88it/s]\u001b[A\n",
      "token features:  93%|█████████▎| 13/14 [00:02<00:00,  4.67it/s]\u001b[A\n",
      "token features: 100%|██████████| 14/14 [00:02<00:00,  5.30it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.31it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  40%|████      | 2/5 [00:00<00:00,  8.71it/s]\u001b[A\n",
      "token features:  60%|██████    | 3/5 [00:00<00:00,  7.47it/s]\u001b[A\n",
      "token features:  80%|████████  | 4/5 [00:00<00:00,  6.94it/s]\u001b[A\n",
      "token features: 100%|██████████| 5/5 [00:00<00:00,  6.48it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 88.80it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "token features:  12%|█▎        | 2/16 [00:00<00:01, 12.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  19%|█▉        | 3/16 [00:00<00:01,  9.11it/s]\u001b[A\n",
      "token features:  25%|██▌       | 4/16 [00:00<00:01,  7.84it/s]\u001b[A\n",
      "token features:  31%|███▏      | 5/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
      "token features:  38%|███▊      | 6/16 [00:00<00:01,  6.25it/s]\u001b[A\n",
      "token features:  44%|████▍     | 7/16 [00:01<00:01,  5.91it/s]\u001b[A\n",
      "token features:  50%|█████     | 8/16 [00:01<00:01,  5.70it/s]\u001b[A\n",
      "token features:  56%|█████▋    | 9/16 [00:01<00:01,  5.35it/s]\u001b[A\n",
      "token features:  62%|██████▎   | 10/16 [00:01<00:01,  5.12it/s]\u001b[A\n",
      "token features:  69%|██████▉   | 11/16 [00:01<00:01,  4.98it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 12/16 [00:02<00:00,  4.88it/s]\u001b[A\n",
      "token features:  81%|████████▏ | 13/16 [00:02<00:00,  4.67it/s]\u001b[A\n",
      "token features:  88%|████████▊ | 14/16 [00:02<00:00,  4.54it/s]\u001b[A\n",
      "token features:  94%|█████████▍| 15/16 [00:02<00:00,  4.42it/s]\u001b[A\n",
      "token features: 100%|██████████| 16/16 [00:03<00:00,  5.20it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 87.46it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "token features:  20%|██        | 2/10 [00:00<00:00, 12.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  30%|███       | 3/10 [00:00<00:00,  9.08it/s]\u001b[A\n",
      "token features:  40%|████      | 4/10 [00:00<00:00,  7.81it/s]\u001b[A\n",
      "token features:  50%|█████     | 5/10 [00:00<00:00,  6.82it/s]\u001b[A\n",
      "token features:  60%|██████    | 6/10 [00:00<00:00,  6.27it/s]\u001b[A\n",
      "token features:  70%|███████   | 7/10 [00:01<00:00,  5.76it/s]\u001b[A\n",
      "token features:  80%|████████  | 8/10 [00:01<00:00,  5.59it/s]\u001b[A\n",
      "token features:  90%|█████████ | 9/10 [00:01<00:00,  5.30it/s]\u001b[A\n",
      "token features: 100%|██████████| 10/10 [00:01<00:00,  5.82it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 88.64it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  20%|██        | 2/10 [00:00<00:00,  8.84it/s]\u001b[A\n",
      "token features:  30%|███       | 3/10 [00:00<00:00,  7.69it/s]\u001b[A\n",
      "token features:  40%|████      | 4/10 [00:00<00:00,  7.07it/s]\u001b[A\n",
      "token features:  50%|█████     | 5/10 [00:00<00:00,  6.41it/s]\u001b[A\n",
      "token features:  60%|██████    | 6/10 [00:00<00:00,  6.02it/s]\u001b[A\n",
      "token features:  70%|███████   | 7/10 [00:01<00:00,  5.75it/s]\u001b[A\n",
      "token features:  80%|████████  | 8/10 [00:01<00:00,  5.61it/s]\u001b[A\n",
      "token features:  90%|█████████ | 9/10 [00:01<00:00,  5.32it/s]\u001b[A\n",
      "token features: 100%|██████████| 10/10 [00:01<00:00,  5.69it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 86.30it/s][A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  12%|█▎        | 2/16 [00:00<00:01,  8.98it/s]\u001b[A\n",
      "token features:  19%|█▉        | 3/16 [00:00<00:01,  7.78it/s]\u001b[A\n",
      "token features:  25%|██▌       | 4/16 [00:00<00:01,  7.06it/s]\u001b[A\n",
      "token features:  31%|███▏      | 5/16 [00:00<00:01,  6.43it/s]\u001b[A\n",
      "token features:  38%|███▊      | 6/16 [00:00<00:01,  6.01it/s]\u001b[A\n",
      "token features:  50%|█████     | 8/16 [00:01<00:01,  6.91it/s]\u001b[A\n",
      "token features:  56%|█████▋    | 9/16 [00:01<00:01,  6.07it/s]\u001b[A\n",
      "token features:  62%|██████▎   | 10/16 [00:01<00:01,  5.59it/s]\u001b[A\n",
      "token features:  69%|██████▉   | 11/16 [00:01<00:00,  5.28it/s]\u001b[A\n",
      "token features:  75%|███████▌  | 12/16 [00:01<00:00,  5.08it/s]\u001b[A\n",
      "token features:  81%|████████▏ | 13/16 [00:02<00:00,  4.81it/s]\u001b[A\n",
      "token features:  88%|████████▊ | 14/16 [00:02<00:00,  4.62it/s]\u001b[A\n",
      "token features:  94%|█████████▍| 15/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      "token features: 100%|██████████| 16/16 [00:02<00:00,  5.47it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 90.57it/s]\u001b[A\n",
      "Using cls_token, but it is not set yet.\n",
      "\n",
      "token features:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "token features:  14%|█▍        | 2/14 [00:00<00:01,  8.90it/s]\u001b[A\n",
      "token features:  21%|██▏       | 3/14 [00:00<00:01,  7.75it/s]\u001b[A\n",
      "token features:  29%|██▊       | 4/14 [00:00<00:01,  7.06it/s]\u001b[A\n",
      "token features:  36%|███▌      | 5/14 [00:00<00:01,  6.34it/s]\u001b[A\n",
      "token features:  43%|████▎     | 6/14 [00:00<00:01,  5.99it/s]\u001b[A\n",
      "token features:  50%|█████     | 7/14 [00:01<00:01,  5.72it/s]\u001b[A\n",
      "token features:  57%|█████▋    | 8/14 [00:01<00:01,  5.58it/s]\u001b[A\n",
      "token features:  64%|██████▍   | 9/14 [00:01<00:00,  5.29it/s]\u001b[A\n",
      "token features:  71%|███████▏  | 10/14 [00:01<00:00,  5.10it/s]\u001b[A\n",
      "token features:  79%|███████▊  | 11/14 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "token features:  86%|████████▌ | 12/14 [00:02<00:00,  4.87it/s]\u001b[A\n",
      "token features:  93%|█████████▎| 13/14 [00:02<00:00,  4.68it/s]\u001b[A\n",
      "token features: 100%|██████████| 14/14 [00:02<00:00,  5.27it/s]\u001b[A\n",
      "\n",
      "layer packaging:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 13/13 [00:00<00:00, 89.81it/s]\u001b[A\n",
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.57it/s]\u001b[A\n",
      "22it [00:00, 82.09it/s]\u001b[A\n",
      "layers:   8%|▊         | 1/13 [01:05<13:11, 66.00s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_1_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 86.62it/s]\u001b[A\n",
      "22it [00:00, 82.21it/s]\u001b[A\n",
      "layers:  15%|█▌        | 2/13 [01:08<08:35, 46.85s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_2_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.83it/s]\u001b[A\n",
      "22it [00:00, 81.13it/s]\u001b[A\n",
      "layers:  23%|██▎       | 3/13 [01:10<05:34, 33.45s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_3_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 86.54it/s]\u001b[A\n",
      "22it [00:00, 82.25it/s]\u001b[A\n",
      "layers:  31%|███       | 4/13 [01:12<03:36, 24.11s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_4_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.64it/s]\u001b[A\n",
      "22it [00:00, 81.85it/s]\u001b[A\n",
      "layers:  38%|███▊      | 5/13 [01:14<02:20, 17.53s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_5_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.15it/s]\u001b[A\n",
      "22it [00:00, 81.29it/s]\u001b[A\n",
      "layers:  46%|████▌     | 6/13 [01:17<01:30, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_6_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 87.14it/s]\u001b[A\n",
      "22it [00:00, 82.68it/s]\u001b[A\n",
      "layers:  54%|█████▍    | 7/13 [01:19<00:58,  9.80s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_7_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.29it/s]\u001b[A\n",
      "22it [00:00, 81.63it/s]\u001b[A\n",
      "layers:  62%|██████▏   | 8/13 [01:21<00:37,  7.51s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_8_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.89it/s]\u001b[A\n",
      "22it [00:00, 78.50it/s]\u001b[A\n",
      "layers:  69%|██████▉   | 9/13 [01:23<00:23,  5.92s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_9_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 85.95it/s]\u001b[A\n",
      "22it [00:00, 82.22it/s]\u001b[A\n",
      "layers:  77%|███████▋  | 10/13 [01:26<00:14,  4.79s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_10_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.74it/s]\u001b[A\n",
      "22it [00:00, 82.44it/s]\u001b[A\n",
      "layers:  85%|████████▍ | 11/13 [01:28<00:08,  4.01s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_11_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.02it/s]\u001b[A\n",
      "22it [00:00, 81.58it/s]\u001b[A\n",
      "layers:  92%|█████████▏| 12/13 [01:30<00:03,  3.46s/it]/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extracting network activations for gpt2\n",
      "\n",
      "\n",
      "ud_sentencez_token_filter_v3_sample_gpt2_layer_12_activation_ave_False_group_2.pkl doesn't exists, creating...\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-44 : And , together we formed this thing , it 's sort of like an entertainment team\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-45 : great knowledge and prices compared to anyone in the industry\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-46 : Heald noted the findings show pollution reduction is also important\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-47 : He was ordained as a Baptist minister\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-48 : I understood it was an Oath to ALL of our people\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-49 : For me it is n't about fulfillment or finding my life 's purpose in my work\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-50 : This Auster was the first intelligent person he had spoken to in a long time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-51 : My hair looks amazing , and I get compliments all the time\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-52 : This could n't be farther from the truth\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-53 : Consider basing your language on an existing language\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-54 : But it has outlived its usefulness , and Microsoft no longer wants to support it\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-55 : Eventually when he found his brother he had resolution\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-56 : Fred and George had spotted their friend from Hogwarts , Lee Jordan\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-57 : My fries were n't fully cooked last time I went there\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-58 : Make sure the shelter box has no nails or safety hazards\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-59 : You should call your vet now and ask them what is normal or not\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-60 : He did warm it up\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-61 : Stir the oil and vanilla extract into the bowl containing the soy milk and vinegar\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-62 : Claimed he was too busy for two test drives\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-63 : Senior US diplomats and military officials have warned India also\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-64 : We highly recommend Joe and his wasp removal service to individual home owners and condos\n",
      "\n",
      "running ud_sentencez_token_filter_v3_sample_group_2-65 : The British Airways chicken with the chill of death upon it lies before me\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xarray/core/dataarray.py:218: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif isinstance(data, pd.Panel):\n",
      "/usr/local/lib/python3.7/site-packages/brainio_base/assemblies.py:224: FutureWarning: The inplace argument has been deprecated and will be removed in a future version of xarray.\n",
      "  xr_data.set_index(append=True, inplace=True, **coords_d)\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 84.59it/s]\u001b[A\n",
      "22it [00:00, 81.82it/s]\u001b[A\n",
      "layers: 100%|██████████| 13/13 [01:32<00:00,  7.12s/it]\n"
     ]
    }
   ],
   "source": [
    "test(group_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
