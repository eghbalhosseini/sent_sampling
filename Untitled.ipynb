{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "#import utils\n",
    "#importlib.reload(utils)\n",
    "from utils.data_utils import SENTENCE_CONFIG, load_obj\n",
    "from neural_nlp.models import model_pool\n",
    "import utils.extract_utils\n",
    "importlib.reload(utils.extract_utils)\n",
    "from utils.extract_utils import model_extractor_parallel\n",
    "\n",
    "from neural_nlp.utils import ordered_set\n",
    "from neural_nlp.stimuli import load_stimuli, StimulusSet\n",
    "from neural_nlp.models import model_pool, model_layers\n",
    "from neural_nlp import FixedLayer\n",
    "from brainio_base.assemblies import DataAssembly, walk_coords, merge_data_arrays, array_is_element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=[list(str(x) for x in np.arange(10)) for x in range(3)]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '1', '2',\n",
       "       '3', '4', '5', '6', '7', '8', '9', '0', '1', '2', '3', '4', '5',\n",
       "       '6', '7', '8', '9'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset='coca_spok_filter_punct_10K_sample_1'\n",
    "#dataset='coca_spok_filter_punct_sample'\n",
    "datafile=[x['file_loc'] for x in SENTENCE_CONFIG if x['name']==dataset][0]\n",
    "model_name='gpt2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /Users/eghbalhosseini/MyData/COCA_corpus/parsed/coca_spok_data_filter_ngram_punct_10K_sample_1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1111it [00:00, 203106.47it/s]\n",
      "1111it [00:00, 203026.83it/s]\n",
      "1111it [00:00, 217162.44it/s]\n",
      "1111it [00:00, 198825.44it/s]\n",
      "1111it [00:00, 214355.39it/s]\n",
      "1111it [00:00, 223946.16it/s]\n",
      "1111it [00:00, 204946.64it/s]\n",
      "1111it [00:00, 217334.63it/s]\n",
      "1112it [00:00, 212292.49it/s]\n"
     ]
    }
   ],
   "source": [
    "test=model_extractor_parallel(dataset=dataset,datafile=datafile,model_spec=model_name,average_sentence=False)\n",
    "\n",
    "test.load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.extractor.stimuli_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_set=test.extractor.stimuli_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_impl = model_pool[test.model_spec]\n",
    "layers = model_layers[test.model_spec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "candidate = FixedLayer(model_impl, layers[0], prerun=layers if i==0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_column='sentence_id'\n",
    "copy_columns=['stimulus_id']\n",
    "activations = []\n",
    "for i, reset_id in enumerate(ordered_set(stimulus_set[reset_column].values)):\n",
    "    part_stimuli = stimulus_set[stimulus_set[reset_column] == reset_id]\n",
    "    stimulus_ids = part_stimuli['stimulus_id']\n",
    "    sentence_stimuli = StimulusSet({'sentence': ' '.join(part_stimuli['word']),\n",
    "                                        reset_column: list(set(part_stimuli[reset_column]))})\n",
    "    sentence_stimuli.name = f\"{stimulus_set.name}-{reset_id}\"\n",
    "    print(f\"running {sentence_stimuli.name} : {' '.join(part_stimuli['word'])}\\n\")\n",
    "    sentence_activations = candidate(stimuli=sentence_stimuli, average_sentence=False)\n",
    "    for column in copy_columns:\n",
    "            sentence_activations[column] = ('presentation', part_stimuli[column])\n",
    "    activations.append(sentence_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_activations = merge_data_arrays(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /Users/eghbalhosseini/Desktop/ud_sentencez_token_filter_v3_sample_gpt2_layer_0_activation_group_8.pkl\n"
     ]
    }
   ],
   "source": [
    "x=load_obj('/Users/eghbalhosseini/Desktop/ud_sentencez_token_filter_v3_sample_gpt2_layer_0_activation_group_8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.NeuroidAssembly 'sentence_id' (presentation: 276)>\n",
       "array([177, 177, 177, ..., 199, 199, 199])\n",
       "Coordinates:\n",
       "  * presentation       (presentation) MultiIndex\n",
       "  - stimulus_sentence  (presentation) object 'All it takes is two twist ties and a few seconds of patience' ... 'He and his wife took over the Silver Rhino last year'\n",
       "  - word               (presentation) object 'All' 'it' ... 'took' 'over'\n",
       "  - sentence           (presentation) object 'All it takes is two twist ties and a few seconds of patience' ... 'He and his wife took over the Silver Rhino last year'\n",
       "  - sentence_id        (presentation) int64 177 177 177 177 ... 179 179 179 179\n",
       "  - stimulus_id        (presentation) int64 0 1 2 3 4 5 6 ... 24 25 26 27 28 29"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['sentence_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-nlp-master",
   "language": "python",
   "name": "neural-nlp-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
